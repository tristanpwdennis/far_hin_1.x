{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3aa47a48-e59e-4d07-b7ef-44b2bd934f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libs and setup environment\n",
    "\n",
    "import allel\n",
    "import seaborn as sns\n",
    "import zarr\n",
    "import xarray as xr\n",
    "import plotly.express as px\n",
    "import dask.array as da\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import json\n",
    "import hashlib\n",
    "import numba\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from Bio import SeqIO\n",
    "from pathlib import Path\n",
    "\n",
    "# Define metadata and qc bool globally to start\n",
    "#define useful variables\n",
    "zarr_base_path = f\"/scratch/user/uqtdenni/afar_production_bunya/curation/uq-beebe-001/combined_zarr/{{contig}}.zarr\"\n",
    "\n",
    "# Let's start by converting zarrs for the 5 largest contigs - we can do QC on them...\n",
    "ref_path = '/scratch/user/uqtdenni/afar_production_bunya/reference/VectorBase-54_AfarautiFAR1_Genome.fasta'\n",
    "# now let's get a list of the contigs that we are going to call over\n",
    "contig_lengths = {}\n",
    "for record in SeqIO.parse(ref_path, \"fasta\"):\n",
    "    seq_id = record.id\n",
    "    seq_length = len(record.seq)\n",
    "    contig_lengths[seq_id] = seq_length\n",
    "filtered_contigs = {k: v for k, v in sorted(contig_lengths.items(), key=lambda item: item[1], reverse=True) if v > 100000}\n",
    "\n",
    "# Because these data are unstaged, we need to faff about a bit more and load the unstaged metadata to exclude extra dud samples\n",
    "df_samples_dirty = pd.read_csv('/scratch/user/uqtdenni/far_hin_1.x/work/metadata_development_20250702/sample_metadata_interim_seq_qc_pass.txt', index_col = 'derived_sample_id')\n",
    "# And load the final (cleaned) metadata\n",
    "df_samples = pd.read_csv('/scratch/user/uqtdenni/far_hin_1.x/work/metadata_development_20250702/sample_metadata_pass_qc.txt', index_col = 'derived_sample_id')\n",
    "\n",
    "# Mask removing samples we removed before the staging step of QC (that I haven't done yet)\n",
    "qc_bool = df_samples_dirty.index.isin(df_samples.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0dee1ad8-8334-46d0-b9d2-076aaebd7b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define helper functions\n",
    "\n",
    "zarr_base_path = f\"/scratch/user/uqtdenni/afar_production_bunya/curation/uq-beebe-001/combined_zarr/{{contig}}.zarr\"\n",
    "\n",
    "def hash_params(*args, **kwargs):\n",
    "    \"\"\"Helper function to hash analysis parameters.\"\"\"\n",
    "    o = {\n",
    "        'args': args,\n",
    "        'kwargs': kwargs\n",
    "    }\n",
    "    s = json.dumps(o, sort_keys=True).encode()\n",
    "    h = hashlib.md5(s).hexdigest()\n",
    "    return h\n",
    "\n",
    "def load_genotype_array(contig, qc_bool=qc_bool, df_samples=df_samples, sample_query = None):\n",
    "    # Load gts and remove failed qc samples\n",
    "    z = zarr.open(zarr_base_path.format(contig = contig))\n",
    "    gt = allel.GenotypeChunkedArray(z[f\"{contig}/calldata/GT\"])\n",
    "    gt = gt.compress(qc_bool, axis=1)\n",
    "    # If an additional mask is supplied to subset the data from the finished metadata, apply, else return all samples\n",
    "    if sample_query is not None:\n",
    "        bool_query = np.array(df_samples.eval(sample_query))\n",
    "        return gt.compress(bool_query, axis=1)\n",
    "    else:\n",
    "        return gt\n",
    "\n",
    "def compute_fst(ac1, ac2, scheme):\n",
    "    \n",
    "    if scheme == 'first':\n",
    "        loc_asc = ac1.is_segregating()\n",
    "    elif scheme == 'second':\n",
    "        loc_asc = ac2.is_segregating()\n",
    "    elif scheme == 'either':\n",
    "        loc_asc = ac1.is_segregating() | ac2.is_segregating()\n",
    "    elif scheme == 'both':\n",
    "        loc_asc = ac1.is_segregating() & ac2.is_segregating()    \n",
    "    n_snps = np.count_nonzero(loc_asc)\n",
    "    \n",
    "    ac1 = ac1.compress(loc_asc, axis=0)\n",
    "    ac2 = ac2.compress(loc_asc, axis=0)\n",
    "    \n",
    "    fst, se, _, _ = allel.blockwise_hudson_fst(ac1, ac2, blen=10000)\n",
    "    \n",
    "    print('%.04f +/- %.04f (using %s SNPs segregating in %s population)' % (fst, se, n_snps, scheme))\n",
    "\n",
    "def compute_ac(contig, qc_bool=qc_bool, df_samples=df_samples, sample_query = None):\n",
    "    gt = load_genotype_array(contig, qc_bool, df_samples, sample_query)\n",
    "    return(gt.count_alleles())\n",
    "    \n",
    "def fst_gwss(sample_query_a, sample_query_b, contig, window_size):\n",
    "    \n",
    "    z = zarr.open(zarr_base_path.format(contig = contig))\n",
    "\n",
    "    ac_a = compute_ac(contig, qc_bool, df_samples, sample_query_a)\n",
    "    ac_b = compute_ac(contig, qc_bool, df_samples, sample_query_b)\n",
    "\n",
    "    pos =  np.array((z[f\"{contig}/variants/POS\"]))\n",
    "    \n",
    "    fst = allel.moving_hudson_fst(ac_a, ac_b, size=window_size)\n",
    "    # Sometimes Fst can be very slightly below zero, clip for simplicity.\n",
    "    \n",
    "    fst = np.clip(fst, a_min=0.0, a_max=1)\n",
    "\n",
    "    x = allel.moving_statistic(pos, statistic=np.mean, size=window_size)    \n",
    "        \n",
    "    return(x, fst)\n",
    "    \n",
    "def fst_analysis(sample_query_a,sample_query_b, contig, window_size, results_dir='results_cache'):\n",
    "    \n",
    "    params = dict(\n",
    "            sample_query_a=sample_query_a,\n",
    "            sample_query_b=sample_query_b,\n",
    "            contig=contig,\n",
    "            window_size=window_size,\n",
    "        )\n",
    "\n",
    "     # construct a key to save the results under\n",
    "    results_key = hash_params(\n",
    "        params\n",
    "    )\n",
    "\n",
    "    # define paths for results files\n",
    "    fst_path = f'{results_dir}/{results_key}-fst.csv'\n",
    "    x_path = f'{results_dir}/{results_key}-x.npy'\n",
    "\n",
    "    try:\n",
    "        # try to load previously generated results\n",
    "        fst = np.load(fst_path)\n",
    "        x = np.load(x_path)\n",
    "        return (fst, x)\n",
    "    except FileNotFoundError:\n",
    "        # no previous results available, need to run analysis\n",
    "        print(f'running analysis: {results_key}')\n",
    "    \n",
    "    print('setting up inputs')\n",
    "\n",
    "    results = fst_gwss(**params)\n",
    "\n",
    "    x = results[0]\n",
    "    fst = results[1]\n",
    "\n",
    "    np.save(fst_path, fst)\n",
    "    np.save(x_path, x)\n",
    "    print(f'saved results: {results_key}')\n",
    "\n",
    "    return (fst, x)\n",
    "\n",
    "\n",
    "def plot_fst(sample_query_a,\n",
    "             sample_query_b,\n",
    "             winsize,\n",
    "             title\n",
    "             ):\n",
    "\n",
    "    df_contigs = []\n",
    "\n",
    "    # Progress bar for contigs\n",
    "    for contig in filtered_contigs.keys():\n",
    "        \n",
    "        f,p = fst_analysis(sample_query_a,sample_query_b,contig, winsize)\n",
    "        \n",
    "        scan_df = pd.DataFrame({'contig':contig,'pos' : p, 'fst':f})\n",
    "\n",
    "        df_contigs.append(scan_df)\n",
    "\n",
    "    # Concatenate df and save out\n",
    "    df = pd.concat(df_contigs)\n",
    "\n",
    "    # Sort contigs by length (longest first)\n",
    "    contig_lengths = df.groupby('contig')['pos'].max()\n",
    "    sorted_contigs = contig_lengths.sort_values(ascending=False).index.tolist()\n",
    "    sorted_lengths = contig_lengths.loc[sorted_contigs]\n",
    "    contig_offsets = sorted_lengths.cumsum().shift(fill_value=0)\n",
    "\n",
    "    df['contig'] = pd.Categorical(df['contig'], categories=sorted_contigs, ordered=True)\n",
    "    df = df.sort_values(['contig', 'pos']).copy()\n",
    "    df['contig_offset'] = df['contig'].map(contig_offsets).astype(float)\n",
    "    df['genome_position'] = df['pos'] + df['contig_offset']\n",
    "\n",
    "    color_map = {\n",
    "        contig: ('lightblue' if i % 2 == 0 else 'steelblue')\n",
    "        for i, contig in enumerate(sorted_contigs)\n",
    "    }\n",
    "    df['color'] = df['contig'].map(color_map)\n",
    "\n",
    "    fig = px.line(\n",
    "        df,\n",
    "        x='genome_position',\n",
    "        y='fst',\n",
    "        color='contig',\n",
    "        color_discrete_map=color_map,\n",
    "        labels={'genome_position': 'Genomic Position', 'fst': \"Hudson's Fst\"},\n",
    "        hover_data = ['pos'],\n",
    "        template = 'simple_white',\n",
    "        title=title\n",
    "    )\n",
    "\n",
    "    fig.update_traces(marker=dict(size=3))  \n",
    "    fig.update_layout(showlegend=False)\n",
    "\n",
    "    \n",
    "    fig.show(renderer=\"iframe\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d0bcc5-b0eb-4862-83da-829a3c4878b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_fst(sample_query_a = 'species_pca == \"hinesorum\" & admin1_iso == \"SB-WE\"',\n",
    "         sample_query_b = 'species_pca == \"hinesorum\" & admin1_iso == \"SB-GU\"',\n",
    "         winsize=100_000,\n",
    "         title = 'Fst, SB-WE:SB-GU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5eaa66ca-7031-46b5-bfb3-d36dd46f71c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running analysis: af32f806db78cd5926faf571b3e84b2b\n",
      "setting up inputs\n",
      "saved results: af32f806db78cd5926faf571b3e84b2b\n",
      "running analysis: ea6ea0cab40eecbfdd6ee232a631eea5\n",
      "setting up inputs\n",
      "saved results: ea6ea0cab40eecbfdd6ee232a631eea5\n",
      "running analysis: 9c9fc73c8fa7172911b1780f4b9f7ed3\n",
      "setting up inputs\n",
      "saved results: 9c9fc73c8fa7172911b1780f4b9f7ed3\n",
      "running analysis: 787b65c21106e95ae9722dc6692332ce\n",
      "setting up inputs\n",
      "saved results: 787b65c21106e95ae9722dc6692332ce\n",
      "running analysis: 4e8c1294b0ed5c839157c49d847cb21c\n",
      "setting up inputs\n",
      "saved results: 4e8c1294b0ed5c839157c49d847cb21c\n",
      "running analysis: 693fddb3984a46f892a9a2094c3418b5\n",
      "setting up inputs\n",
      "saved results: 693fddb3984a46f892a9a2094c3418b5\n",
      "running analysis: 80c59f39afbf6ac4d9750d901f3e7e37\n",
      "setting up inputs\n",
      "saved results: 80c59f39afbf6ac4d9750d901f3e7e37\n",
      "running analysis: 097f7732bc8f329c21f4dc36e6d874c1\n",
      "setting up inputs\n",
      "saved results: 097f7732bc8f329c21f4dc36e6d874c1\n",
      "running analysis: e8ad02f62a3b5c52e75ecf3ad1a39cbf\n",
      "setting up inputs\n",
      "saved results: e8ad02f62a3b5c52e75ecf3ad1a39cbf\n",
      "running analysis: b2c5aa22554757c9b8f2e24dbb981da8\n",
      "setting up inputs\n",
      "saved results: b2c5aa22554757c9b8f2e24dbb981da8\n",
      "running analysis: 33e57f38f0e1d169682792ba5ff456f7\n",
      "setting up inputs\n",
      "saved results: 33e57f38f0e1d169682792ba5ff456f7\n",
      "running analysis: a9432b3f0f6a90222ecb1400148cac3d\n",
      "setting up inputs\n",
      "saved results: a9432b3f0f6a90222ecb1400148cac3d\n",
      "running analysis: 1d38afc736674e81b62d64912b423b94\n",
      "setting up inputs\n",
      "saved results: 1d38afc736674e81b62d64912b423b94\n",
      "running analysis: 7e43b9acbee0d85b3e9448fec63fd6f9\n",
      "setting up inputs\n",
      "saved results: 7e43b9acbee0d85b3e9448fec63fd6f9\n",
      "running analysis: faad558f32db7db858d641aba2b49863\n",
      "setting up inputs\n",
      "saved results: faad558f32db7db858d641aba2b49863\n",
      "running analysis: a23e6e455f464e61899d01359cdb0536\n",
      "setting up inputs\n",
      "saved results: a23e6e455f464e61899d01359cdb0536\n",
      "running analysis: b616c4bf3ffc5a6ba55ac1a70e3db3a2\n",
      "setting up inputs\n",
      "saved results: b616c4bf3ffc5a6ba55ac1a70e3db3a2\n",
      "running analysis: 2e7ba45c998ccef1bda6d0124d14d023\n",
      "setting up inputs\n",
      "saved results: 2e7ba45c998ccef1bda6d0124d14d023\n",
      "running analysis: 80553768e2939c7fe6beb85a30915ea1\n",
      "setting up inputs\n",
      "saved results: 80553768e2939c7fe6beb85a30915ea1\n",
      "running analysis: 1da733e41b3217c3e1b33524919319a1\n",
      "setting up inputs\n",
      "saved results: 1da733e41b3217c3e1b33524919319a1\n",
      "running analysis: 0a31f54168bf68a5655df199d1e3c5c4\n",
      "setting up inputs\n",
      "saved results: 0a31f54168bf68a5655df199d1e3c5c4\n",
      "running analysis: 69eb55154e6857ffafe42c8743e942f4\n",
      "setting up inputs\n",
      "saved results: 69eb55154e6857ffafe42c8743e942f4\n",
      "running analysis: cbaff9e9c087b289d1e38cbb0c6f8eaa\n",
      "setting up inputs\n",
      "saved results: cbaff9e9c087b289d1e38cbb0c6f8eaa\n",
      "running analysis: 9d30cbe8d76134bf6f9cd35164cd7b63\n",
      "setting up inputs\n",
      "saved results: 9d30cbe8d76134bf6f9cd35164cd7b63\n",
      "running analysis: 3b4e2ca667d1e80d89bf621654cd9c73\n",
      "setting up inputs\n",
      "saved results: 3b4e2ca667d1e80d89bf621654cd9c73\n",
      "running analysis: 8041a97d4302e2b1c68798de1ba50040\n",
      "setting up inputs\n",
      "saved results: 8041a97d4302e2b1c68798de1ba50040\n",
      "running analysis: 2d5134415dd007a08473337e4e7e242b\n",
      "setting up inputs\n",
      "saved results: 2d5134415dd007a08473337e4e7e242b\n",
      "running analysis: 146f0d2780616b20f9e11410a115db67\n",
      "setting up inputs\n",
      "saved results: 146f0d2780616b20f9e11410a115db67\n",
      "running analysis: f4d84be01dbe220d7a66476a3abcaa96\n",
      "setting up inputs\n",
      "saved results: f4d84be01dbe220d7a66476a3abcaa96\n",
      "running analysis: aabf360c4a0c2278da1523c554253bae\n",
      "setting up inputs\n",
      "saved results: aabf360c4a0c2278da1523c554253bae\n",
      "running analysis: 2aa0605ef46e5b4b7216610bb1c5ec3c\n",
      "setting up inputs\n",
      "saved results: 2aa0605ef46e5b4b7216610bb1c5ec3c\n",
      "running analysis: 2990aaf919d38f5f391ac54ff76a1b14\n",
      "setting up inputs\n",
      "saved results: 2990aaf919d38f5f391ac54ff76a1b14\n",
      "running analysis: 36f7abe171b1062f4d95799db935e3d7\n",
      "setting up inputs\n",
      "saved results: 36f7abe171b1062f4d95799db935e3d7\n",
      "running analysis: 9021944a8c226523961c8c2c351f4816\n",
      "setting up inputs\n",
      "saved results: 9021944a8c226523961c8c2c351f4816\n",
      "running analysis: 0528bf108f13c7698af5b17730daa293\n",
      "setting up inputs\n",
      "saved results: 0528bf108f13c7698af5b17730daa293\n",
      "running analysis: 10b4a38814e2c3e694da30c503c23768\n",
      "setting up inputs\n",
      "saved results: 10b4a38814e2c3e694da30c503c23768\n",
      "running analysis: 5242efc8d12528a9ace232a71e1ed7cd\n",
      "setting up inputs\n",
      "saved results: 5242efc8d12528a9ace232a71e1ed7cd\n",
      "running analysis: 5873edf3022660772e7d2c82f85cc68f\n",
      "setting up inputs\n",
      "saved results: 5873edf3022660772e7d2c82f85cc68f\n",
      "running analysis: 1758a061bc729e5384d286c4cd66ead4\n",
      "setting up inputs\n",
      "saved results: 1758a061bc729e5384d286c4cd66ead4\n",
      "running analysis: 35300013e7f82b0406a5591b550ca9db\n",
      "setting up inputs\n",
      "saved results: 35300013e7f82b0406a5591b550ca9db\n",
      "running analysis: 87447f4944faf6fe9936ec60a4128381\n",
      "setting up inputs\n",
      "saved results: 87447f4944faf6fe9936ec60a4128381\n",
      "running analysis: 52219493f7a280e1bd767406263051a0\n",
      "setting up inputs\n",
      "saved results: 52219493f7a280e1bd767406263051a0\n",
      "running analysis: e5c588d7c7bdf1f059c93cb36edccd53\n",
      "setting up inputs\n",
      "saved results: e5c588d7c7bdf1f059c93cb36edccd53\n",
      "running analysis: cb9261710eea53a8ceabb18828036659\n",
      "setting up inputs\n",
      "saved results: cb9261710eea53a8ceabb18828036659\n",
      "running analysis: eee20bfe5b4276d3dba2bfa6068fd2ae\n",
      "setting up inputs\n",
      "saved results: eee20bfe5b4276d3dba2bfa6068fd2ae\n",
      "running analysis: 147c91b183e18fd997ac7593e7b91060\n",
      "setting up inputs\n",
      "saved results: 147c91b183e18fd997ac7593e7b91060\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_7.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_fst(sample_query_a = 'species_pca == \"hinesorum\" & admin1_iso == \"SB-WE\"',\n",
    "         sample_query_b = 'species_pca == \"hinesorum\" & admin1_iso == \"PG-MBA\"',\n",
    "         winsize=50_000,\n",
    "         title = 'Fst, SB-WE:PG-MBA')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "far_hin_1.x",
   "language": "python",
   "name": "far_hin_1.x"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
